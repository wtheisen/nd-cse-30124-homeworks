{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence - Homework Assignment 04 (20pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NETIDs:\n",
    "\n",
    "This assignment covers the following topics:\n",
    "\n",
    "* Feed-Forward Neural Networks\n",
    "* Gradient Descent and Backpropagation\n",
    "* Convolutional Neural Networks\n",
    "\n",
    "It will consist of 5 tasks (with an optional 6th bonus task):\n",
    "\n",
    "| Task ID  | Description                                      | Points |\n",
    "|----------|--------------------------------------------------|--------|\n",
    "| 00       | Load Dataset                                     | 0      |\n",
    "| 01       | Feed-Forward Neural Network                |        |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-1     | &nbsp;&nbsp;&nbsp;&nbsp;- Linear Layer                   | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-2     | &nbsp;&nbsp;&nbsp;&nbsp;- ReLU Activation Function                  | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-3     | &nbsp;&nbsp;&nbsp;&nbsp;- Feed-Forward Neural Network                  | 5      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-4     | &nbsp;&nbsp;&nbsp;&nbsp;- FFN Eval                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-5     | &nbsp;&nbsp;&nbsp;&nbsp;- FFN Target Accuracy                 | 1      |\n",
    "| 02       | Torch Feed-Foward Neural Network               |        |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-1     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch FFN Definition                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-2     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch FFN Training Function                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-3     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch FFN Evaluation                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-4     | &nbsp;&nbsp;&nbsp;&nbsp;- FFN Short Answer Questions                 | 2      |\n",
    "| 03       | Torch Convolutional Neural Network               |        |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-1     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch CNN Definition                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-2     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch CNN Training Function                 | 1      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-3     | &nbsp;&nbsp;&nbsp;&nbsp;- Torch CNN Evaluation                 | 2      |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-4     | &nbsp;&nbsp;&nbsp;&nbsp;- CNN Short Answer Questions                 | 2      |\n",
    "| 04       | Final OCR Evaluation                              | 0      |\n",
    "| 05       | **Bonus Task:** Convolutional Neural Network                             | +3     |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;05-1     | &nbsp;&nbsp;&nbsp;&nbsp;- Convolutional Layer                 |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;05-2     | &nbsp;&nbsp;&nbsp;&nbsp;- Max Pooling Layer                |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;05-3     | &nbsp;&nbsp;&nbsp;&nbsp;- Flattening Layer                 |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;05-4     | &nbsp;&nbsp;&nbsp;&nbsp;- Convolutional Neural Network                 |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;05-5     | &nbsp;&nbsp;&nbsp;&nbsp;- CNN Eval                 |       |\n",
    "\n",
    "Please complete all non-bonus sections. Some questions may require written answers, while others may involve coding. Be sure to run your code cells to verify your solutions.\n",
    "\n",
    "### *Story Progression*\n",
    "Now that you have the segmented letters from the previous task, we need a way to actually convert the letters to text! You can't be bothered to just transcribe the images yourself, but you remember your professor droning on about something called MNIST and you think that these letters might be kind of similar to handwritten digits.\n",
    "\n",
    "Unfortunately because your professor hates you, he's making you write a FFN using only tensors for the first part of this assignment. Use the dataset available from the github for training, testing, and validation on this assignment.\n",
    "\n",
    "## Task 00: Load Dataset\n",
    "### Task 00: Description (0 pts.)\n",
    "#### Loading the EMNIST Subset Dataset\n",
    "\n",
    "In class several times we've seen the MNIST dataset, the kidnapping letters are similar but they contain alphabet characters, so we need to use something slightly different to train our OCR models for this task. Luckily their exists an extended version of MNIST --- EMNIST that has not only the handwritten digits, but the handwritten alphabet as well. We can use a subset of this dataset to train our OCR models. Below I've added code to load in the dataset and convert it all to tensors for you.\n",
    "\n",
    "### Task 00: Code (0 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cnf5vqf8qzrt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    REPO_URL = \"https://github.com/nd-cse-30124-fa25/cse-30124-homeworks.git\"\n",
    "    REPO_NAME = \"cse-30124-homeworks\"\n",
    "    HW_FOLDER = \"homework04\" \n",
    "\n",
    "    # Clone repo if not already present\n",
    "    if not os.path.exists(REPO_NAME):\n",
    "        !git clone {REPO_URL}\n",
    "\n",
    "    # cd into the homework folder\n",
    "    %cd {REPO_NAME}/{HW_FOLDER}\n",
    "\n",
    "except ImportError:\n",
    "    pass\n",
    "    \n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for xb, yb in self.dataloader:\n",
    "            yield xb.to(self.device), yb.to(self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "def load_dataset(data_name, device='cpu', batch_size=128, val_fraction=0.1, seed=42):\n",
    "    DATA_FOLDER = f'{data_name}'\n",
    "    TRAIN_FILE = f\"{DATA_FOLDER}/{data_name}_train.npz\"\n",
    "    TEST_FILE  = f\"{DATA_FOLDER}/{data_name}_test.npz\"\n",
    "    CLASSES_FILE = f\"{DATA_FOLDER}/classes.json\"\n",
    "\n",
    "    # Seeds\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    use_pin = (device.type == \"cuda\")  # pin_memory mainly benefits CUDA\n",
    "\n",
    "    # ---- Load arrays: X: (N, 28, 28) uint8, y: (N,) int64 ----\n",
    "    train_npz = np.load(TRAIN_FILE)\n",
    "    X_train = train_npz[\"X\"]\n",
    "    y_train = train_npz[\"y\"]\n",
    "\n",
    "    test_npz = np.load(TEST_FILE)\n",
    "    X_test = test_npz[\"X\"]\n",
    "    y_test = test_npz[\"y\"]\n",
    "\n",
    "    with open(CLASSES_FILE, \"r\") as f:\n",
    "        classes = json.load(f)[\"classes\"]\n",
    "\n",
    "    num_classes = len(classes)\n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}, Classes: {num_classes}\")\n",
    "\n",
    "    # ---- Tensors for batch-first CNNs ----\n",
    "    # scale to [0,1], add channel dim -> (N, 1, 28, 28); labels stay indices (N,)\n",
    "    X_train_t = torch.from_numpy(X_train).to(torch.float32).div(255.0).unsqueeze(1)\n",
    "    y_train_t = torch.from_numpy(y_train).to(torch.long)\n",
    "    X_test_t  = torch.from_numpy(X_test ).to(torch.float32).div(255.0).unsqueeze(1)\n",
    "    y_test_t  = torch.from_numpy(y_test ).to(torch.long)\n",
    "\n",
    "    full_train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    test_ds       = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "    # ---- Train/Val split ----\n",
    "    n_train = len(full_train_ds)\n",
    "    n_val   = math.ceil(n_train * val_fraction)\n",
    "    n_main  = n_train - n_val\n",
    "    train_ds, val_ds = random_split(\n",
    "        full_train_ds, [n_main, n_val],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    # ---- DataLoaders (batch-first) ----\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, persistent_workers=False, pin_memory=use_pin\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, persistent_workers=False, pin_memory=use_pin\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, persistent_workers=False, pin_memory=use_pin\n",
    "    )\n",
    "\n",
    "    train_loader = DeviceDataLoader(train_loader, device)\n",
    "    val_loader   = DeviceDataLoader(val_loader, device)\n",
    "    test_loader  = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "    print(f\"Train/Val/Test sizes: {len(train_ds)}/{len(val_ds)}/{len(test_ds)}\")\n",
    "    return train_loader, val_loader, test_loader, num_classes, classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01: Feed-Forward Neural Network\n",
    "### Task 01-1: Description (0 pts.)\n",
    "#### Linear Layer\n",
    "\n",
    "The best way to fully understand neural networks is to implement one from scratch. To that end you'll need to write classes for each component of a neural network that you'll need to use in your model. After waiting until the day before it's due to start this homework and with much wailing and gnashing of teeth many of you will say `“Why do we have to write the backward pass when frameworks in the real world, such as TensorFlow, compute them for you automatically?”`. To this end you may be well served by perusing this [blogpost](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b) by one of the most famous AI researchers, Andrej Karpathy, titled `Yes you should understand backprop`. It starts with the following paragraph:\n",
    "\n",
    "```\n",
    "When we offered CS231n (Deep Learning class) at Stanford, we intentionally designed the programming assignments to include explicit calculations involved in backpropagation on the lowest level. The students had to implement the forward and the backward pass of each layer in raw numpy.\n",
    "```\n",
    "\n",
    "If you fully understand this assignment, and the first part of Homework05, you will have an extremely strong understanding of the fundamentals of deep learning. These are hard assignments however, so don't get frustrated.\n",
    "\n",
    " We're going to start with a \"LinearLayer\" or the layer that will perform the linear transformation between the input, weights, and biases. Each component of our model will have 3 functions:\n",
    "\n",
    "1. `forward(self, X)`\n",
    "2. `backward(self, dA)`\n",
    "3. `update(self, lr)`\n",
    "\n",
    "However not every component will make use of these 3, for example, a `ReLU` doesn't have weights so while we need the function stub to call as we iterate through our layers, the `ReLU` itself has no weights to update and ass such will just `pass`. In the code cell below, implement the 3 functions needed for the `LinearLayer`.\n",
    "\n",
    "### Task 01-1: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    \"\"\"\n",
    "    Fully connected layer that applies an affine transform in batch-first format.\n",
    "\n",
    "    Attributes:\n",
    "        W (torch.Tensor): Weight matrix of shape (output_dim, input_dim).\n",
    "        b (torch.Tensor): Bias row vector of shape (1, output_dim).\n",
    "        device (torch.device): Device storing the parameters.\n",
    "        X (torch.Tensor): Cached batch input from the latest forward pass.\n",
    "        dW (torch.Tensor): Gradient of the loss with respect to `W`.\n",
    "        db (torch.Tensor): Gradient of the loss with respect to `b`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, device='cpu'):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases with He normal initialization.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of input features per example.\n",
    "            output_dim (int): Number of output features produced by the layer.\n",
    "            device (torch.device or str): Device on which to allocate the parameters.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "\n",
    "        self.W = torch.randn(output_dim, input_dim, device=self.device) * math.sqrt(2.0 / input_dim)\n",
    "        self.b = torch.randn(1, output_dim, device=self.device) * math.sqrt(2.0 / input_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Apply the affine transform to a batch and cache the input for backward().\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input batch of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output batch of shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Store the input and calculate and return the output of the linear layer\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backpropagate the gradient through the affine transform.\n",
    "\n",
    "        Args:\n",
    "            dA (torch.Tensor): Upstream gradient of shape (batch_size, output_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient with respect to the input of shape (batch_size, input_dim).\n",
    "\n",
    "        Side Effects:\n",
    "            Populates `dW` and `db` for use during the subsequent update().\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the gradient of the loss with respect to the weights and biases\n",
    "\n",
    "        # TODO: Return the gradient of the loss with respect to the input\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Apply an in-place gradient descent step using the stored gradients.\n",
    "\n",
    "        Args:\n",
    "            lr (float): Learning rate for the parameter update.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Update the weights and biases of the layer using the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01-2: Description (0 pts.)\n",
    "#### Rectified Linear Unit (ReLU) Activation Function\n",
    "\n",
    "We now need to write our first activation function, we're going to use the ReLU due to its speed and simplcity.\n",
    "\n",
    "### Task 01-2: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    Element-wise rectified linear activation.\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Apply ReLU activation and cache the input tensor.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input tensor of any shape.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor with negatives zeroed out, same shape as `X`.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Store the input and calculate and return the output of the ReLU layer\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Propagate gradients through the ReLU non-linearity.\n",
    "\n",
    "        Args:\n",
    "            dA (torch.Tensor): Upstream gradient matching the shape of the forward output.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient with respect to the input, zeroed where the cached input was non-positive.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate and return the gradient of the loss with respect to the input\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Keep API parity with trainable layers; ReLU has no parameters to update.\n",
    "\n",
    "        Args:\n",
    "            lr (float): Unused learning rate argument.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # TODO: Update the weights and biases of the layer using the learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01-3: Description (0 pts.)\n",
    "#### Numpy Feed-Forward Neural Network Model Class\n",
    "\n",
    "The previous 2 classes: `LinearLayer` and `ReLU` are all we need to implement a very simple FFN. We can stack a combination of these together and add a training loop to it and we should be good to go!\n",
    "\n",
    "### Task 01-3: Code (5 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Feed-forward network assembled from the custom Linear, ReLU, and Softmax layers.\n",
    "\n",
    "    The model consumes flattened EMNIST images `(batch_size, 784)` and produces\n",
    "    probability distributions over 47 balanced EMNIST classes.\n",
    "\n",
    "    Attributes:\n",
    "        device (torch.device): Device used for parameters and computation.\n",
    "        layers (list): Ordered sequence of layers applied during forward().\n",
    "    \"\"\"\n",
    "    def __init__(self, device='cpu', seed=42):\n",
    "        \"\"\"\n",
    "        Build the fully connected architecture and seed the random generator.\n",
    "\n",
    "        Args:\n",
    "            device (torch.device or str): Device used for tensors and parameters.\n",
    "            seed (int): Random seed for deterministic weight initialization.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # TODO: Define better model architecture\n",
    "        L1 = LinearLayer(784, 47, device=self.device)\n",
    "        softmax = Softmax()\n",
    "\n",
    "        self.layers = [L1, softmax]\n",
    "\n",
    "    def forward(self, X, eval=False):\n",
    "        \"\"\"\n",
    "        Sequentially apply each layer in the network.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Batch of flattened images of shape (batch_size, 784).\n",
    "            eval (bool): If True, return the softmax of the output of the network.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits or Probabilities of shape (batch_size, 47) depending on eval.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the output of the network\n",
    "\n",
    "    def softmax(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (torch.Tensor): Input data with shape (n_classes, m), where n_classes is the number of classes\n",
    "                               and m is the number of examples.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Softmax probabilities with shape (n_classes, m).\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the softmax of the input\n",
    "\n",
    "    def cross_entropy(self, logits, Y):\n",
    "        \"\"\"\n",
    "        Compute the mean cross-entropy loss for one-hot encoded targets.\n",
    "\n",
    "        Args:\n",
    "            logits (torch.Tensor): Predicted logits of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scalar loss tensor averaged over the batch.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate and return the cross-entropy loss\n",
    "\n",
    "    def get_accuracy(self, logits, Y):\n",
    "        \"\"\"\n",
    "        Calculate classification accuracy for one-hot encoded labels.\n",
    "\n",
    "        Args:\n",
    "            logits (torch.Tensor): Predicted logits of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scalar tensor containing the accuracy fraction.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate and return the accuracy of the network\n",
    "\n",
    "    def backprop(self, logits, Y):\n",
    "        \"\"\"\n",
    "        Backpropagate the cross-entropy gradient through all layers.\n",
    "\n",
    "        Args:\n",
    "            logits (torch.Tensor): Predicted logits of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Side Effects:\n",
    "            Updates each layer's cached gradients in preparation for parameter updates.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the gradient of the loss with respect to the input\n",
    "\n",
    "    def data_shaper(self, loader, num_classes=47):\n",
    "        \"\"\"\n",
    "        Adapt DataLoader batches to the flattened representation expected by the network.\n",
    "\n",
    "        Args:\n",
    "            loader (Iterable): DataLoader yielding `(images, labels)` batches.\n",
    "            num_classes (int): Number of classes for one-hot encoding.\n",
    "\n",
    "        Yields:\n",
    "            tuple[torch.Tensor, torch.Tensor]: Flattened images `(batch_size, 784)` and\n",
    "            one-hot labels `(batch_size, num_classes)`.\n",
    "        \"\"\"\n",
    "        for xb, yb in loader:\n",
    "            X_batch = xb.flatten(start_dim=1)  # Reshape to (784, m)\n",
    "            Y_batch = torch.eye(num_classes, dtype=torch.float32, device=self.device)[yb]\n",
    "\n",
    "            yield X_batch, Y_batch\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=100, learning_rate=0.001, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the network using mini-batch gradient descent on the provided loaders.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): Iterable that yields training batches.\n",
    "            val_loader (DataLoader): Iterable that yields validation batches.\n",
    "            epochs (int): Number of epochs to iterate over the training data.\n",
    "            learning_rate (float): Step size used during gradient descent updates.\n",
    "            verbose (bool): If True, log metrics every 10 epochs.\n",
    "\n",
    "        Returns:\n",
    "            dict: Contains `loss_history` and `accuracy_history` measured on the validation data.\n",
    "        \"\"\"\n",
    "        loss_history = []\n",
    "        accuracy_history = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for X_batch, Y_batch in self.data_shaper(train_loader):\n",
    "                # Forward propagation\n",
    "                # TODO: Calculate the output of the network\n",
    "                \n",
    "                # Backward propagation\n",
    "                # TODO: Calculate the gradients of the loss with respect to the input\n",
    "                \n",
    "                # Update parameters\n",
    "                # TODO: Update the weights and biases of the layer using the learning rate\n",
    "            \n",
    "            for X_batch, Y_batch in self.data_shaper(val_loader):\n",
    "                # Calculate metrics for the whole epoch on the validation set\n",
    "                Y_hat_full = self.forward(X_batch)\n",
    "                loss = self.cross_entropy(Y_hat_full, Y_batch)\n",
    "                accuracy = self.get_accuracy(Y_hat_full, Y_batch)\n",
    "                \n",
    "                loss_history.append(loss)\n",
    "                accuracy_history.append(accuracy)\n",
    "            \n",
    "            if verbose and i % 10 == 0:\n",
    "                print(f\"Epoch {i+1}/{epochs}\")\n",
    "                print(f\"loss: {loss:.5f}\")\n",
    "                print(f\"accuracy: {accuracy:.5f}\")\n",
    "                print(\"-\" * 30)\n",
    "        \n",
    "        return {'loss_history': loss_history, 'accuracy_history': accuracy_history}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRdFPk8aqzrv"
   },
   "source": [
    "### Task 01-4: Description (0 pts.)\n",
    "#### FFN Evaluation\n",
    "\n",
    "The cell below will allow you to evaluate the performance of your FFN on the holdout set. Instead of giving hard values, which is basically impossible in deep learning, I'll be giving you a target output accuracy instead. Your goal is to reach `75%` accuracy on the holdout set. You'll almost certainly have to test a number of different combinations of architectures and hyperparameters.\n",
    "\n",
    "### Task 01-4: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42Z7gBmCqzrw"
   },
   "outputs": [],
   "source": [
    "def evaluate_on_holdout(test_loader, model):\n",
    "    \"\"\"\n",
    "    Evaluate a trained scratch model on a holdout DataLoader.\n",
    "\n",
    "    Args:\n",
    "        test_loader (DataLoader): Loader providing holdout `(images, labels)` batches.\n",
    "        model (NeuralNetwork): Trained network exposing `data_shaper`, `forward`, and `get_accuracy`.\n",
    "\n",
    "    Returns:\n",
    "        list: Accuracy values for each holdout batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = []\n",
    "    # Get predictions\n",
    "    for X_batch, Y_batch in model.data_shaper(test_loader):\n",
    "        y_pred = model.forward(X_batch)\n",
    "        accuracy.append(model.get_accuracy(y_pred, Y_batch))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Initialize and train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "train_loader, val_loader, test_loader, num_classes, classes = load_dataset('emnist_balanced_small', device=device)\n",
    "\n",
    "\n",
    "model = NeuralNetwork(device=device)\n",
    "history = model.train(train_loader, val_loader)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "holdout_accuracy = evaluate_on_holdout(test_loader, model)\n",
    "print(f\"Holdout set accuracy: {torch.mean(torch.tensor(holdout_accuracy)):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01-5: Target Accuracy (1 pt.)\n",
    "`75%`\n",
    "\n",
    "### Task 01-5: Reference Output (0 pts.)\n",
    "\n",
    "Below is what my training run looked like when I passed the target `75%` accuracy but it's possible yours may look slightly different, this is just intended to give you a general idea of what the numbers should look like.\n",
    "\n",
    "```\n",
    "Train: (9400, 28, 28), Test: (2350, 28, 28), Classes: 47\n",
    "Train/Val/Test sizes: 8460/940/2350\n",
    "Epoch 1/100\n",
    "loss: 2.03566\n",
    "accuracy: 0.40909\n",
    "------------------------------\n",
    "Epoch 11/100\n",
    "loss: 0.88603\n",
    "accuracy: 0.77273\n",
    "------------------------------\n",
    "Epoch 21/100\n",
    "loss: 1.00684\n",
    "accuracy: 0.68182\n",
    "------------------------------\n",
    "Epoch 31/100\n",
    "loss: 0.95293\n",
    "accuracy: 0.72727\n",
    "------------------------------\n",
    "Epoch 41/100\n",
    "loss: 0.96932\n",
    "accuracy: 0.77273\n",
    "------------------------------\n",
    "Epoch 51/100\n",
    "loss: 1.10004\n",
    "accuracy: 0.72727\n",
    "------------------------------\n",
    "Epoch 61/100\n",
    "loss: 1.17194\n",
    "accuracy: 0.70455\n",
    "------------------------------\n",
    "Epoch 71/100\n",
    "loss: 1.11888\n",
    "accuracy: 0.77273\n",
    "------------------------------\n",
    "Epoch 81/100\n",
    "loss: 1.23379\n",
    "accuracy: 0.72727\n",
    "------------------------------\n",
    "Epoch 91/100\n",
    "loss: 1.29806\n",
    "accuracy: 0.70455\n",
    "------------------------------\n",
    "Holdout set accuracy: 0.75602\n",
    "```\n",
    "\n",
    "## Task 02: Description (0 pts.)\n",
    "### Task 02-1: Description (0 pts.)\n",
    "#### Comparison to pytorch FFN implementation\n",
    "\n",
    "Lets see how the FFN you wrote from scratch compares to a pytorch implementation! Make sure to use the same model architecture you used for your model! I'd encourage you to refer back to the notebook for the practicum to see a basic torch FFN model implementation.\n",
    "\n",
    "### Task 02-1: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, num_classes=47):\n",
    "        super().__init__()\n",
    "        # TODO: Define model architecture\n",
    "        self.fc1 = nn.Linear(784, 47)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # He init for ReLU layers\n",
    "        for m in [self.fc1, self.fc2, self.fc3]:\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "            nn.init.zeros_(m.bias)\n",
    "        # Last layer: slightly smaller std to avoid huge initial logits\n",
    "        nn.init.kaiming_normal_(self.fc4.weight, nonlinearity=\"linear\")\n",
    "        nn.init.zeros_(self.fc4.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Calculate and return the output of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-2: Description (0 pts.)\n",
    "#### Torch FFN Training Loop\n",
    "\n",
    "Now that we've defined our model architecture, lets write a training loop for it.\n",
    "\n",
    "### Task 02-2: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device, epochs=100, lr=1e-3):\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            # TODO: Run model training step\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "                f\"train_loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "                f\"val_loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-3: Description (0 pts.)\n",
    "#### Torch FFN Evaluation and Comparison\n",
    "\n",
    "Now that we've defined our model architecture, lets write a training loop for it.\n",
    "\n",
    "### Task 02-3: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct, running_loss = 0, 0, 0.0\n",
    "    for xb, yb in loader:\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "    avg_loss = running_loss / max(total, 1)\n",
    "    acc = correct / max(total, 1)\n",
    "    return avg_loss, acc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "train_loader, val_loader, test_loader, num_classes, classes = load_dataset(\"emnist_balanced_small\", device=device)\n",
    "model = MLP(num_classes=num_classes)\n",
    "\n",
    "model = train(model, train_loader, val_loader, device, epochs=100, lr=1e-3)\n",
    "test_loss, test_acc = evaluate(model, test_loader, device)\n",
    "print(f\"TEST  | loss {test_loss:.4f} acc {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEs1r9Elqzrw"
   },
   "source": [
    "### Task 02-3: Reference Output (0 pts.)\n",
    "\n",
    "```\n",
    "Train: (9400, 28, 28), Test: (2350, 28, 28), Classes: 47\n",
    "Train/Val/Test sizes: 8460/940/2350\n",
    "Epoch 10/100 | train_loss 0.2911 acc 0.9035 | val_loss 0.8697 acc 0.7415\n",
    "Epoch 20/100 | train_loss 0.0705 acc 0.9754 | val_loss 1.0084 acc 0.7628\n",
    "Epoch 30/100 | train_loss 0.1041 acc 0.9649 | val_loss 1.3578 acc 0.7191\n",
    "Epoch 40/100 | train_loss 0.0191 acc 0.9936 | val_loss 1.3311 acc 0.7713\n",
    "Epoch 50/100 | train_loss 0.0168 acc 0.9944 | val_loss 1.4263 acc 0.7649\n",
    "Epoch 60/100 | train_loss 0.1100 acc 0.9631 | val_loss 1.6886 acc 0.7138\n",
    "Epoch 70/100 | train_loss 0.0068 acc 0.9983 | val_loss 1.6452 acc 0.7755\n",
    "Epoch 80/100 | train_loss 0.0181 acc 0.9934 | val_loss 1.7808 acc 0.7532\n",
    "Epoch 90/100 | train_loss 0.0043 acc 0.9992 | val_loss 1.7345 acc 0.7436\n",
    "Epoch 100/100 | train_loss 0.0003 acc 1.0000 | val_loss 1.8476 acc 0.7543\n",
    "TEST  | loss 2.0233 acc 0.7472\n",
    "```\n",
    "\n",
    "### Task 02-4: FFN Short Answer Questions (2 pts.)\n",
    "\n",
    "* What is the general intuition behind more layers generally improving our model?\n",
    "    * [ANSWER]\n",
    "\n",
    "* How do the number of epochs and learning rate interact?\n",
    "    * [ANSWER]\n",
    "\n",
    "### *Story Progression*\n",
    "\n",
    "Wow, your model worked almost exactly as well as the one using the state-of-the-art library! That's pretty cool but while the FFN is okay, it's really not that well suited to image classification tasks such as this. Fighting through the hangover, you recall something about the news channel CNN? Implement a CNN (using pytorch) below and see if you can get a better result than the FFN.\n",
    "\n",
    "## Task 03: Convolutional Neural Network\n",
    "### Task 03-1: Description (0 pts.)\n",
    "#### CNN Model Definition\n",
    "\n",
    "Below we're going to implement a CNN in torch, CNNs are pretty tricky so if you don't want any bonus points we'll just stop with the torch version of it.\n",
    "\n",
    "### Task 03-1: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=47):\n",
    "        super().__init__()\n",
    "        #TODO: Define the neural network architecture\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO: Calculate the output of the network in the forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 03-2: Description (0 pts.)\n",
    "#### Torch CNN Training Loop\n",
    "\n",
    "Now that we've defined our model architecture, lets write a training loop for it, luckily this will look very similar to our FFN loop, which is one of the reasons libraries like pytorch are so nice.\n",
    "\n",
    "### Task 03-2: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHOavdLHqzrw"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=100 ,learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train a PyTorch CNN and track train/validation metrics.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Convolutional network to optimize in-place.\n",
    "        train_loader (DataLoader): DataLoader supplying training batches.\n",
    "        val_loader (DataLoader): DataLoader supplying validation batches.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        learning_rate (float): Learning rate for the Adam optimizer.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[float], list[float], list[float]]: Histories for training loss, training accuracy (percent),\n",
    "        and validation accuracy (percent).\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    criterion = F.nll_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # TODO: Train the model\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # TODO: Validate model on validation set\n",
    "        \n",
    "        val_acc = 100. * correct / total\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, '\n",
    "                f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    return train_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 03-3: Description (0 pts.)\n",
    "#### CNN Training and Eval\n",
    "\n",
    "In the cell below we'll write the helper function to train and evaluate our CNN model.\n",
    "\n",
    "### Task 03-3: Code (1 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQkxyr9zqzrw"
   },
   "outputs": [],
   "source": [
    "def run_basic_cnn_experiment(train_loader, val_loader, test_loader):\n",
    "    # Initialize model and training components\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = CNN().to(device)\n",
    "    \n",
    "    # Train model\n",
    "    train_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, num_epochs=100)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # TODO: Evaluate on holdout set\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    holdout_acc = 100. * correct / total\n",
    "    print(f'Holdout Accuracy: {holdout_acc:.2f}%')\n",
    "    \n",
    "    return model, (train_losses, train_accs, val_accs, holdout_acc)\n",
    "\n",
    "# Run basic CNN experiment\n",
    "print(\"Running Basic CNN Experiment...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "train_loader, val_loader, test_loader, num_classes, classes = load_dataset('emnist_balanced_small', device=device)\n",
    "model, basic_metrics = run_basic_cnn_experiment(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecHzhz5Mqzrx"
   },
   "source": [
    "### Task 03-3: Target Accuracy (1 pt.)\n",
    "`80%` on Holdout Set\n",
    "\n",
    "### Task 03-3: Reference Output (0 pts.)\n",
    "\n",
    "Instead of expected output, I'll give you the reference output from my run that managed to clear the `80%` threshold but don't expect yours to necessarily be identical.\n",
    "\n",
    "```\n",
    "Running Basic CNN Experiment...\n",
    "Train: (9400, 28, 28), Test: (2350, 28, 28), Classes: 47\n",
    "Train/Val/Test sizes: 8460/940/2350\n",
    "Epoch [50/100], Loss: 0.1541, Train Acc: 94.53%, Val Acc: 77.02%\n",
    "Epoch [100/100], Loss: 0.0181, Train Acc: 99.52%, Val Acc: 80.43%\n",
    "Holdout Accuracy: 80.77%\n",
    "```\n",
    "\n",
    "### Task 03-4: CNN Short Answer Questions (2 pts.)\n",
    "\n",
    "* What makes the CNN a more natural fit for working with images?\n",
    "    * [ANSWER]\n",
    "\n",
    "* Why do we have both Convolutional Layers and Linear Layers in our network?\n",
    "    * [ANSWER]\n",
    "\n",
    "## Task 04: Inference on Segmented Letters\n",
    "### Task 04: Description (0 pts.)\n",
    "\n",
    "Now that we have a model that we've trained to perform OCR, lets actually try and run it on the characters we extracted from the kidnapping letters on Homework03! We can then compare our predicted characters to the ground truth from the letters to see how well our combined segmentation + OCR actually did (not that well sadly)! Run the code below to perform the evaluation.\n",
    "\n",
    "### Task 04: Code (0 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class SegmentedLetterDataset(Dataset):\n",
    "    \"\"\"Dataset that loads segmented note letter PNGs for inference.\"\"\"\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"Directory not found: {self.image_dir}\")\n",
    "        self.image_paths = sorted(self.image_dir.glob('*.png'), key=self._sort_key)\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No PNG files found in {self.image_dir}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    @staticmethod\n",
    "    def _sort_key(path):\n",
    "        parts = path.stem.split('_')\n",
    "        note_idx = int(parts[1])\n",
    "        letter_idx = int(parts[3])\n",
    "        return note_idx, letter_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path.name\n",
    "\n",
    "def load_segmented_letter_loader(image_dir='segmented_letter_images', batch_size=32):\n",
    "    \"\"\"Create a DataLoader over all segmented letter PNGs.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = SegmentedLetterDataset(image_dir, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "seg_loader = load_segmented_letter_loader()\n",
    "with open(Path('emnist_balanced_small') / 'classes.json', 'r') as f:\n",
    "    CLASSES = json.load(f)['classes']\n",
    "\n",
    "if 'model' not in globals():\n",
    "    raise RuntimeError('Train the CNN model (Task 03) before running Task 04 inference.')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "pred_indices = []\n",
    "file_names = []\n",
    "with torch.no_grad():\n",
    "    for images, names in seg_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        pred_indices.extend(outputs.argmax(dim=1).cpu().tolist())\n",
    "        file_names.extend(names)\n",
    "\n",
    "note_messages = defaultdict(str)\n",
    "for name, idx in zip(file_names, pred_indices):\n",
    "    parts = name.replace('.png', '').split('_')\n",
    "    note_id = parts[1]\n",
    "    note_messages[note_id] += CLASSES[idx]\n",
    "\n",
    "decoded_notes = {f'note_{note_id}': note_messages[note_id] for note_id in sorted(note_messages, key=int)}\n",
    "\n",
    "ground_truth_output = [\n",
    "    'V YBIRQ ZHEQREVAT ZE GURVFRASYBLQ NG GUR RFGNGR GUR TNF JNF GUR CRESRPG ZHEQRE JRNCBA',\n",
    "    'VZ FHER VYY TRG NJNL JVGU VG NF JRYY UBCRSHYYL ABOBQL SVTHERF BHG GUR',\n",
    "    'PBZOVANGVBA BS GUR CNQYBPX CYNL BA YBPXRE 69 BA GUR FRPBAQ SYBBE BS PHFUVAT',\n",
    "    'BGUREJVFR V NZ VA ERNY GEBHOYR'\n",
    "]\n",
    "\n",
    "for note_id, text in decoded_notes.items():\n",
    "    print(f'{note_id}:')\n",
    "    print(f'\\tExpected:  {ground_truth_output[int(note_id[5])]}')\n",
    "\n",
    "    spaced_output = ''\n",
    "    space_offset = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for idx, gt_char in enumerate(ground_truth_output[int(note_id[5])]):\n",
    "        if gt_char == ' ':\n",
    "            spaced_output += ' '\n",
    "            space_offset += 1\n",
    "        else:\n",
    "            try:\n",
    "                spaced_output += text[idx - space_offset]\n",
    "                if spaced_output[-1] != gt_char:\n",
    "                    error_count += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(f\"\\tPredicted: {spaced_output}\")\n",
    "    print(f'\\tAccuracy:    {(len(text) - error_count) / len(text):.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 04-1: Reference Output\n",
    "Here is my output for Task 04-1 but if you managed to train a better model than me you may beat my results!\n",
    "\n",
    "```\n",
    "note_0:\n",
    "\tExpected:  V YBIRQ ZHEQREVAT ZE GURVFRASYBLQ NG GUR RFGNGR GUR TNF JNF GUR CRESRPG ZHEQRE JRNCBA\n",
    "\tPredicted: V 8BqBQ ZqB8REVA8 ZE BBRVPqASVBDQ nB BUP 3GGnGR BgB ZJG 3NG GBR CqIgRPG 88BBOP EJBWaB\n",
    "\tAccuracy:    0.3889\n",
    "\n",
    "note_1:\n",
    "\tExpected:  VZ FHER VYY TRG NJNL JVGU VG NF JRYY UBCRSHYYL ABOBQL SVTHERF BHG GUR\n",
    "\tPredicted: Vq BqER JVq JBG NNNL 3VBU VB NP DRqV VBgRgHDbA B0BBDS VqqBBfB qGG Ua\n",
    "\tAccuracy:    0.3091\n",
    "\n",
    "note_2:\n",
    "\tExpected:  PBZOVANGVBA BS GUR CNQYBPX CYNL BA YBPXRE 69 BA GUR FRPBAQ SYBBE BS PHFUVAT\n",
    "\tPredicted: PBZDVGnBVBB Bg BBa CNB8BPX gYNL qA XBPXPE Be Gn BBq PBPqAO 8SXBB BB SPqPBVA\n",
    "\tAccuracy:    0.3968\n",
    "\n",
    "note_3:\n",
    "\tExpected:  BGUREJVFR V NZ VA ERNY GEBHOYR\n",
    "\tPredicted: BGB3E8VPq V JJ VA EBnB GBBqOYR\n",
    "\tAccuracy:    0.5200\n",
    "```\n",
    "\n",
    "The results here are pretty inaccurate. One reason is that it's reliant on our cropping from Homework03 working well and it's reliant on the training data looking similar to the test data, which isn't exactly the case here. All things considered though, I think it does pretty well.\n",
    "\n",
    "### *Story Progression*\n",
    "\n",
    "Unfortunately, despite having the text, you still can't read it. It appears to be encoded with some kind of cipher. If only there were seq2seq models that you maybe could use to decode it...\n",
    "\n",
    "## Task 05: Bonus Task\n",
    "### Task 05-1: Description\n",
    "#### Convolutional Neural Network from Scratch\n",
    "\n",
    "For 3 bonus points, you can implement a Convolutional Neural Network from scratch in a manner similar to which you did the FFN. We can reuse our LinearLayer and our Softmax and ReLUs but we're going to need three new components: a `ConvolutionalLayer`, a `MaxPoolingLayer`, and a `FlatteningLayer` (this flatteninglayer is a bit silly but it makes our compositions a little cleaner).\n",
    "\n",
    "It's relatively easy to implement a CNN with a bunch of nested for loops but it then runs extremely slowly so we're going to implement it with a technique called im2col where instead of having a bunch of very small scale matrix multiplications (very slow) we're going to flatten the entire convolutional computation on the entire batch into a singular matrix multiplication (very fast).\n",
    "\n",
    "Our input to our forward pass will be \n",
    "\n",
    "```\n",
    "X (torch.tensor): Input data with shape (N, C_in, H, W) where:\n",
    "                N: batch size\n",
    "                C_in: input channels\n",
    "                H: input height\n",
    "                W: input width\n",
    "```\n",
    "\n",
    "but the computation we want to compute will be on a flattened X with dimensions:\n",
    "\n",
    "```\n",
    "(batch_size * output_width * output_height, input_channels * kernel_size * kernel_size)\n",
    "```\n",
    "\n",
    "Reminder that broadly speaking, a convolution is similar to sliding a kernel around an image.\n",
    "\n",
    "![convolution](https://miro.medium.com/1*D6iRfzDkz-sEzyjYoVZ73w.gif)\n",
    "\n",
    "### Task 05-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class ConvolutionalLayer:\n",
    "    \"\"\"\n",
    "    2D convolution implemented with unfold (im2col) and matrix multiplication.\n",
    "\n",
    "    Attributes:\n",
    "        input_channels (int): Number of expected input channels.\n",
    "        output_channels (int): Number of convolutional filters.\n",
    "        kernel_size (int): Spatial extent of each square kernel.\n",
    "        device (torch.device): Device storing parameters and caches.\n",
    "        dtype (torch.dtype): Precision used for parameters and computations.\n",
    "        flattened_kernels_length (int): Elements per flattened kernel.\n",
    "        W (torch.Tensor): Weight matrix of shape (output_channels, flattened_kernels_length).\n",
    "        b (torch.Tensor): Bias vector of shape (output_channels,).\n",
    "        _X_shape (tuple): Cached input shape from the most recent forward pass.\n",
    "        _cols (torch.Tensor): Cached unfolded input used during backward().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, device='cpu', dtype=torch.float32):\n",
    "        \"\"\"\n",
    "        Create learnable parameters and caches for the convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of filters produced by the layer.\n",
    "            kernel_size (int): Size of the (square) convolutional kernel.\n",
    "            device (torch.device or str): Device on which to allocate the parameters.\n",
    "            dtype (torch.dtype): Data type used for parameters and computations.\n",
    "        \"\"\"\n",
    "        self.input_channels  = in_channels\n",
    "        self.output_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.flattened_kernels_length = self.input_channels * kernel_size * kernel_size\n",
    "\n",
    "        self.W = torch.randn(out_channels, self.flattened_kernels_length, device=self.device, dtype=self.dtype) * math.sqrt(2.0 / self.flattened_kernels_length)\n",
    "        self.b = torch.zeros(out_channels, device=self.device, dtype=self.dtype)\n",
    "\n",
    "        self._X_shape = None\n",
    "        self._cols = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Apply the convolution to a batch of images.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input tensor of shape (batch_size, C_in, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, C_out, H_out, W_out).\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, input_channels, input_height, input_width = X.shape\n",
    "        output_height = input_height - self.kernel_size + 1\n",
    "        output_width = input_width - self.kernel_size + 1\n",
    "\n",
    "        # TODO: Compute the im2col matrix\n",
    "\n",
    "        # TODO: Compute the convolution as a matrix multiplication + bias addition\n",
    "\n",
    "        # TODO: Reshape the output back to (N, C_out, H_out, W_out)\n",
    "\n",
    "        self._X_shape = X.shape\n",
    "        self._cols = cols\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backpropagate gradients through the convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            dA (torch.Tensor): Upstream gradient of shape (batch_size, C_out, H_out, W_out).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient with respect to the input of shape (batch_size, C_in, H, W).\n",
    "\n",
    "        Side Effects:\n",
    "            Stores gradients for `W` and `b` in `dW` and `db`.\n",
    "        \"\"\"\n",
    "        batch_size, input_channels, input_height, input_width = self._X_shape\n",
    "        output_height, output_width = dA.shape[2], dA.shape[3]\n",
    "\n",
    "        flattened_output_length = output_height * output_width\n",
    "\n",
    "        # TODO: Correctly shape dA and self._cols for gradient computations\n",
    "\n",
    "        # TODO: Compute gradients w.r.t. weights and biases\n",
    "\n",
    "        # TODO: Compute gradient w.r.t. input\n",
    "\n",
    "        # TODO: Reshape dcols back to the original input shape\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Apply a gradient descent step to the convolutional parameters.\n",
    "\n",
    "        Args:\n",
    "            lr (float): Learning rate for the parameter update.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # TODO: Update the weights and biases of the layer using the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH0iEqP6qzrx"
   },
   "source": [
    "### Task 05-2: Description\n",
    "#### Max Pooling Layer from Scratch\n",
    "\n",
    "In the cell below we will implement a max pooling layer to run in-between our convolutional layers.\n",
    "\n",
    "![maxpooling](https://i.sstatic.net/6WbWu.png)\n",
    "\n",
    "Reminder that a Max Pooling just passes forward the largest value contained in the patch.\n",
    "\n",
    "### Task 05-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    \"\"\"\n",
    "    Max pooling layer that downsamples by taking the largest value in each non-overlapping window.\n",
    "\n",
    "    Attributes:\n",
    "        kernel_size (int): Edge length of the square pooling window.\n",
    "        _X_shape (tuple): Cached input shape from the forward pass.\n",
    "        _idx (torch.Tensor): Indices of the maxima within each pooling window.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=2):\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # caches for backward\n",
    "        self._X_shape = None\n",
    "        self._idx = None  # argmax in the (kH*kW) window, shape (N, C, H_out, W_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Downsample the input by taking the maximum in each window.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input tensor of shape (batch_size, C_in, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, C_in, H_out, W_out).\n",
    "        \"\"\"\n",
    "        batch_size, num_channels, input_height, input_width = X.shape\n",
    "\n",
    "        # require perfect tiling by the kernel\n",
    "        output_height, output_width = input_height // self.kernel_size, input_width // self.kernel_size\n",
    "\n",
    "        # TODO: Reshape X to get non-overlapping blocks\n",
    "\n",
    "        # TODO: Compute max and argmax in each window\n",
    "\n",
    "        # cache for backward\n",
    "        self._X_shape = (batch_size, num_channels, input_height, input_width)\n",
    "        self._idx = idx.contiguous()\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Route gradients to the inputs that achieved the pooled maxima.\n",
    "\n",
    "        Args:\n",
    "            dA (torch.Tensor): Upstream gradient of shape (batch_size, C_in, H_out, W_out).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient with respect to the input of shape (batch_size, C_in, H, W).\n",
    "        \"\"\"\n",
    "        batch_size, num_channels, input_height, input_width = self._X_shape\n",
    "        output_height, output_width = input_height // self.kernel_size, input_width // self.kernel_size\n",
    "\n",
    "        K = self.kernel_size * self.kernel_size\n",
    "\n",
    "        # TODO: Build one-hot mask in window dim (last) using cached argmax\n",
    "\n",
    "        # TODO: invert the reshape/permutation:\n",
    "        # (N,C,H_out,W_out,K) -> (N,C,H_out,kH,W_out,kW)\n",
    "\n",
    "        # TODO: merge the block dims back to H,W\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Pooling has no parameters, so no update is required.\n",
    "\n",
    "        Args:\n",
    "            lr (float): Unused learning rate argument.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # TODO: Update the weights and biases of the layer using the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 05-3: Description\n",
    "#### Flattening Layer from Scratch\n",
    "\n",
    "The flattening layer isn't really a real thing, but between our Convolutional Layers and Linear Layers we need to flatten our feature vector and for the purpose of continuining to use a single loop, we'll write this flatten layer just to simplify the composition of the components of the model.\n",
    "\n",
    "### Task 05-3: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer:\n",
    "    \"\"\"\n",
    "    Layer that reshapes convolutional feature maps into flat vectors.\n",
    "\n",
    "    Attributes:\n",
    "        input_shape (tuple): Cached shape needed to restore the tensor during backward().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_shape = None  # to remember shape for backward\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Flatten convolutional features while remembering the original shape.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input tensor of shape (batch_size, C_in, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Flattened tensor of shape (batch_size, C_in * H * W).\n",
    "        \"\"\"\n",
    "        self.input_shape = X.shape\n",
    "        # TODO: Flatten X to (N, C*H*W)\n",
    "\n",
    "        return X_flat\n",
    "\n",
    "    def backward(self, dY):\n",
    "        \"\"\"\n",
    "        Restore gradients to the original convolutional feature map shape.\n",
    "\n",
    "        Args:\n",
    "            dY (torch.Tensor): Upstream gradient of shape (batch_size, C_in * H * W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient reshaped to (batch_size, C_in, H, W).\n",
    "        \"\"\"\n",
    "        N, C, H, W = self.input_shape\n",
    "\n",
    "        # TODO: Reshape dY back to the original input shape\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        No parameters to update; method kept for interface consistency.\n",
    "\n",
    "        Args:\n",
    "            lr (float): Unused learning rate argument.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # TODO: Update the weights and biases of the layer using the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 05-4: Description\n",
    "#### Convolutional Neural Network from Scratch\n",
    "\n",
    "Similar to our FFN model, we'll define a CNN Class that will contain all our components and let us train and run our model. You should just use the same model architecture you used for the torch CNN and many of the functions can be re-used from your FFN model.\n",
    "\n",
    "### Task 05-4: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork:\n",
    "    \"\"\"\n",
    "    Convolutional network composed of custom convolution, pooling, and linear layers.\n",
    "\n",
    "    Designed for EMNIST images shaped `(batch_size, 1, 28, 28)` and outputs probabilities\n",
    "    across 47 character classes.\n",
    "\n",
    "    Attributes:\n",
    "        device (torch.device): Device used for parameters and computation.\n",
    "        layers (list): Ordered sequence of layers applied during forward().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device='cpu', seed=42):\n",
    "        \"\"\"\n",
    "        Instantiate the CNN architecture and seed parameter initialization.\n",
    "\n",
    "        Args:\n",
    "            device (torch.device or str): Device used for tensors and parameters.\n",
    "            seed (int): Random seed for deterministic weight initialization.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # TODO: Define better model architecture\n",
    "        \n",
    "        C1 = ConvolutionalLayer(in_channels=1, out_channels=32, kernel_size=5, device=self.device)\n",
    "        P1 = MaxPoolingLayer()\n",
    "        R1 = ReLU()\n",
    "\n",
    "        F1 = FlattenLayer()\n",
    "\n",
    "        L1 = LinearLayer(1024, 128, device=self.device)\n",
    "        softmax = Softmax()\n",
    "\n",
    "        self.layers =  [C1, P1, R1, \n",
    "                        F1,\n",
    "                        L1, softmax]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass a batch of images through all layers of the CNN.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input batch of shape (batch_size, 1, 28, 28).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Probabilities of shape (batch_size, 47).\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the output of the network\n",
    "\n",
    "        return X\n",
    "\n",
    "    def cross_entropy(self, Y_hat, Y):\n",
    "        \"\"\"\n",
    "        Compute mean cross-entropy loss for softmax probabilities.\n",
    "\n",
    "        Args:\n",
    "            Y_hat (torch.Tensor): Predicted probabilities of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scalar loss tensor averaged over the batch.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the cross-entropy loss\n",
    "\n",
    "    def convert_prob_into_class(self, probs):\n",
    "        \"\"\"\n",
    "        Convert probability vectors into predicted class indices.\n",
    "\n",
    "        Args:\n",
    "            probs (torch.Tensor): Probabilities of shape (batch_size, num_classes).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted class indices of shape (batch_size,).\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Convert the probabilities into a class\n",
    "\n",
    "    def get_accuracy(self, Y_hat, Y):\n",
    "        \"\"\"\n",
    "        Compute classification accuracy for one-hot encoded labels.\n",
    "\n",
    "        Args:\n",
    "            Y_hat (torch.Tensor): Predicted probabilities of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scalar tensor containing the accuracy fraction.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the accuracy of the network\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def backprop(self, Y_hat, Y):\n",
    "        \"\"\"\n",
    "        Backpropagate cross-entropy gradients through all CNN layers.\n",
    "\n",
    "        Args:\n",
    "            Y_hat (torch.Tensor): Predicted probabilities of shape (batch_size, num_classes).\n",
    "            Y (torch.Tensor): One-hot encoded targets with the same shape.\n",
    "\n",
    "        Side Effects:\n",
    "            Updates each layer's cached gradients for parameter updates.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate the gradient of the loss with respect to the input\n",
    "\n",
    "    def data_shaper(self, loader, num_classes=47):\n",
    "        \"\"\"\n",
    "        Prepare DataLoader batches for the CNN training loop.\n",
    "\n",
    "        Args:\n",
    "            loader (Iterable): DataLoader yielding `(images, labels)` batches.\n",
    "            num_classes (int): Number of classes for one-hot encoding.\n",
    "\n",
    "        Yields:\n",
    "            tuple[torch.Tensor, torch.Tensor]: Images `(batch_size, 1, 28, 28)` and one-hot\n",
    "            labels `(batch_size, num_classes)`.\n",
    "        \"\"\"\n",
    "        for xb, yb in loader:\n",
    "            Y_batch = torch.eye(num_classes, dtype=torch.float32, device=self.device)[yb]\n",
    "\n",
    "            yield xb, Y_batch\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=100, learning_rate=0.001, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the CNN with mini-batch gradient descent on the provided loaders.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): Iterable that yields training batches.\n",
    "            val_loader (DataLoader): Iterable that yields validation batches.\n",
    "            epochs (int): Number of epochs to iterate over the training data.\n",
    "            learning_rate (float): Step size used during gradient descent updates.\n",
    "            verbose (bool): If True, log metrics every 10 epochs.\n",
    "\n",
    "        Returns:\n",
    "            dict: Contains `loss_history` and `accuracy_history` measured on the validation data.\n",
    "        \"\"\"\n",
    "        loss_history = []\n",
    "        accuracy_history = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for X_batch, Y_batch in self.data_shaper(train_loader):\n",
    "                # Forward propagation\n",
    "                # TODO: Calculate the output of the network\n",
    "                \n",
    "                # Backward propagation\n",
    "                # TODO: Calculate the gradients of the loss with respect to the input\n",
    "                \n",
    "                # Update parameters\n",
    "                # TODO: Update the weights and biases of the layer using the learning rate\n",
    "            \n",
    "            for X_batch, Y_batch in self.data_shaper(val_loader):\n",
    "                # Calculate metrics for the whole epoch on the validation set\n",
    "                Y_hat_full = self.forward(X_batch)\n",
    "                loss = self.cross_entropy(Y_hat_full, Y_batch)\n",
    "                accuracy = self.get_accuracy(Y_hat_full, Y_batch)\n",
    "                \n",
    "                loss_history.append(loss)\n",
    "                accuracy_history.append(accuracy)\n",
    "            \n",
    "            if verbose and i % 10 == 0:\n",
    "                print(f\"Epoch {i+1}/{epochs}\")\n",
    "                print(f\"loss: {loss:.5f}\")\n",
    "                print(f\"accuracy: {accuracy:.5f}\")\n",
    "                print(\"-\" * 30)\n",
    "        \n",
    "        return {'loss_history': loss_history, 'accuracy_history': accuracy_history}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 05-5: Description\n",
    "#### CNN from Scratch Training and Evaluation\n",
    "\n",
    "Now that we have our CNN fully built, lets train it and see how it does on the test set! No target accuracy here, I just think it's neat that it works :) (though I was able to clear the target `80%` with my hand-built one too)\n",
    "\n",
    "### Task 05-5: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_holdout(test_loader, model):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the holdout set\n",
    "\n",
    "    Args:\n",
    "        data_dict: Dictionary containing the dataset splits\n",
    "        model: Trained NumpyNeuralNetwork model\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy on holdout set\n",
    "        np.ndarray: Confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = []\n",
    "    # Get predictions\n",
    "    for X_batch, Y_batch in model.data_shaper(test_loader):\n",
    "        y_pred = model.forward(X_batch)\n",
    "        accuracy.append(model.get_accuracy(y_pred, Y_batch))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# Load dataset\n",
    "train_loader, val_loader, test_loader, num_classes, classes = load_dataset('emnist_balanced_small', device=device)\n",
    "\n",
    "# Initialize and train model\n",
    "model = ConvolutionalNeuralNetwork(device=device)\n",
    "history = model.train(train_loader, val_loader)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "holdout_accuracy = evaluate_on_holdout(test_loader, model)\n",
    "print(f\"Holdout set accuracy: {torch.mean(torch.tensor(holdout_accuracy)):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 05-5: Reference Output\n",
    "\n",
    "```\n",
    "Train: (9400, 28, 28), Test: (2350, 28, 28), Classes: 47\n",
    "Train/Val/Test sizes: 8460/940/2350\n",
    "Epoch 1/100\n",
    "loss: 1.57598\n",
    "accuracy: 0.56818\n",
    "------------------------------\n",
    "Epoch 11/100\n",
    "loss: 0.70333\n",
    "accuracy: 0.77273\n",
    "------------------------------\n",
    "Epoch 21/100\n",
    "loss: 0.79560\n",
    "accuracy: 0.81818\n",
    "------------------------------\n",
    "Epoch 31/100\n",
    "loss: 0.92910\n",
    "accuracy: 0.84091\n",
    "------------------------------\n",
    "Epoch 41/100\n",
    "loss: 1.12943\n",
    "accuracy: 0.81818\n",
    "------------------------------\n",
    "Epoch 51/100\n",
    "loss: 1.19908\n",
    "accuracy: 0.86364\n",
    "------------------------------\n",
    "Epoch 61/100\n",
    "loss: 1.24729\n",
    "accuracy: 0.84091\n",
    "------------------------------\n",
    "Epoch 71/100\n",
    "loss: 1.26052\n",
    "accuracy: 0.86364\n",
    "------------------------------\n",
    "Epoch 81/100\n",
    "loss: 1.40077\n",
    "accuracy: 0.84091\n",
    "------------------------------\n",
    "Epoch 91/100\n",
    "loss: 1.43567\n",
    "accuracy: 0.84091\n",
    "------------------------------\n",
    "Holdout set accuracy: 0.80322\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
